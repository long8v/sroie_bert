{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.append('/home/long8v/BERT-NER')\n",
    "from bert import Ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/long8v/ICDAR-2019-SROIE/task3/data/test_dict.pth'\n",
    "data_dict = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/long8v/ICDAR-2019-SROIE/task3/data/data_dict.pth'\n",
    "data_dict = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {key:value[0] for key, value in data_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/long8v/ICDAR-2019-SROIE/task3/data/keys.pth'\n",
    "key_dict = torch.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ner('/home/long8v/sroie_data/raw_bert_replace_special_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = model.tokenizer\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re_int = re.compile('\\d+')\n",
    "re_float = re.compile('(\\d+\\.\\d+)')\n",
    "re_percent = re.compile('(\\d+.?\\d+%)')\n",
    "re_date = re.compile('(\\d{2}[/-]\\d{2}[/-]\\d{2,4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_dict = {re_float:'float', re_percent:'percent', re_date:'date', re_int:'int'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_text(text):\n",
    "    for key, value in re_dict.items():\n",
    "        text = key.sub(value, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_find_pattern(text):\n",
    "    pattern = re.compile('float|percent|date|int')\n",
    "    if pattern.findall(text):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_find_which_pattern(text):\n",
    "    pattern = re.compile('float|percent|date|int')\n",
    "    try:\n",
    "        return pattern.findall(text)[0]\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_text(text):\n",
    "    patterns = {}\n",
    "    for key, value in re_dict.items():\n",
    "        patterns[value] = re.findall(key, text) \n",
    "        text = key.sub(value, text)\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_word(text):\n",
    "    token_word = tokenizer.tokenize(text)\n",
    "    return token_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data = {}\n",
    "re_data = {}\n",
    "for key, value in data_dict.items():\n",
    "    preprocess_data[key] = preprocess(value)\n",
    "    re_data[key] = get_re_text(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_data = {}\n",
    "for key, value in preprocess_data.items():\n",
    "    result_data[key] = model.predict(value[:512])\n",
    "    result_data[key].extend(model.predict(value[512:1024]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_result_json(result_list):\n",
    "    result_json = defaultdict(list)\n",
    "    re_dict_json = defaultdict(int)\n",
    "    for sample in result_list:\n",
    "        tag = sample['tag'].lower()\n",
    "        word = sample['word']\n",
    "        word = word.replace('##', '')\n",
    "        re_dict_json[re_find_which_pattern(word)] += 1\n",
    "        if tag != 'o':\n",
    "            try:\n",
    "                result_json[tag.split('-')[1]] += [(word, int(re_dict_json[re_find_which_pattern(word)]))]\n",
    "            except Exception as e:\n",
    "                print(tag, e)\n",
    "    return dict(result_json)\n",
    "\n",
    "\n",
    "json_data = {}\n",
    "for key, value in result_data.items():\n",
    "    json_data[key] = get_result_json(value)\n",
    "    new_json_data = {}\n",
    "    for k, v in json_data[key].items():\n",
    "        words = [re_data[key][re_find_which_pattern(word)][count-1] \n",
    "                 if re_find_pattern(word) else word \n",
    "                 for word, count in v]\n",
    "        if words:\n",
    "            words = [re.escape(word) for word in words]\n",
    "            pattern = '\\s?'.join(words)\n",
    "            try:\n",
    "                v_with_space = list(filter(lambda e: e, re.findall(pattern, data_dict[key])))\n",
    "                new_json_data[k] = v_with_space\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    json_data[key] = new_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_data = {}\n",
    "for key, value in json_data.items():\n",
    "    new_dict = defaultdict(str)\n",
    "    for k, v in value.items():\n",
    "        if v:\n",
    "            if k == 'total':\n",
    "                try:\n",
    "                    v = max(list(map(lambda e: float(e), v)))\n",
    "                except ValueError:\n",
    "                    v = ''\n",
    "            else:\n",
    "                v = v[0]\n",
    "        else:\n",
    "            v = ''\n",
    "        new_dict[k] = str(v).replace('\\n', ' ')\n",
    "    new_json_data[key] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '/home/long8v/docrv2_sroie/submission/SROIE_example_t3'\n",
    "for key, value in new_json_data.items():\n",
    "    with open('{}/{}.txt'.format(path, key), 'w') as f:\n",
    "        f.write('{\\n')\n",
    "        f.write('    \"company\": \"{}\",\\n'.format(value['company']))\n",
    "        f.write('    \"date\": \"{}\",\\n'.format(value['date']))\n",
    "        f.write('    \"address\": \"{}\",\\n'.format(value['address']))\n",
    "        f.write('    \"total\": \"{}\"\\n'.format(value['total']))\n",
    "        f.write('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '/home/long8v/docrv2_sroie/submission/SROIE_example_t3'\n",
    "out_path = '/home/long8v/docrv2_sroie/submission/SROIE_example_t3'\n",
    "out_zip_file = '/home/long8v/docrv2_sroie/evaluation/task3/submit.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    " \n",
    "submission_zip = zipfile.ZipFile(out_zip_file, 'w')\n",
    "for folder, subfolders, files in os.walk(in_path): \n",
    "    for file in files:\n",
    "        submission_zip.write(os.path.join(folder, file), \n",
    "                             os.path.relpath(os.path.join(folder,file), out_path), \n",
    "                             compress_type = zipfile.ZIP_DEFLATED)\n",
    "submission_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_hugging_face",
   "language": "python",
   "name": "huggin_face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
