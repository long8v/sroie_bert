{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.append('/home/long8v/BERT-NER')\n",
    "from bert import Ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/long8v/ICDAR-2019-SROIE/task3/data/data_dict.pth'\n",
    "data_dict = torch.load(path)\n",
    "data_dict = {key:value[0] for key, value in data_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ner('/home/long8v/sroie_data/row_token_added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_int = re.compile('\\d+')\n",
    "re_float = re.compile('(\\d+\\.\\d+)')\n",
    "re_percent = re.compile('(\\d+.?\\d+%)')\n",
    "re_date = re.compile('(\\d{2}[/-]\\d{2}[/-]\\d{2,4})')\n",
    "re_row = re.compile('\\n')\n",
    "\n",
    "\n",
    "re_dict = {re_float:'float', re_percent:' percent ', re_date:' date ', re_int:' int ', re_row:' row '}\n",
    "\n",
    "re.findall(re_int, 'NO.33')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_text(text):\n",
    "    for key, value in re_dict.items():\n",
    "        text = key.sub(value, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_find_pattern(text):\n",
    "    pattern = re.compile('float|percent|date|int|row')\n",
    "    if pattern.findall(text):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_find_which_pattern(text):\n",
    "    pattern = re.compile('float|percent|date|int|row')\n",
    "    try:\n",
    "        return pattern.findall(text)[0]\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_text(text):\n",
    "    patterns = {}\n",
    "    for key, value in re_dict.items():\n",
    "        patterns[value.strip()] = re.findall(key, text) \n",
    "        text = key.sub(value, text)\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_word(text):\n",
    "    token_word = tokenizer.tokenize(text)\n",
    "    return token_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data = {}\n",
    "re_data = {}\n",
    "for key, value in data_dict.items():\n",
    "    preprocess_data[key] = preprocess(value)\n",
    "    re_data[key] = get_re_text(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_data = {}\n",
    "for key, value in preprocess_data.items():\n",
    "    result_data[key] = model.prewdict(value[:512])\n",
    "    result_data[key].extend(model.predict(value[512:1024]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/long8v/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from nltk.tree import Tree\n",
    "from nltk.chunk import conlltags2tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_json(result_list):\n",
    "    tokens = [result['word'] for result in result_list]\n",
    "    tags = [result['tag'] for result in result_list]\n",
    "\n",
    "    re_dict_json = defaultdict(int)\n",
    "    result_json = defaultdict(list)\n",
    "    re_dict_json = defaultdict(int)\n",
    "\n",
    "        \n",
    "    pos_tags = [pos for token, pos in pos_tag(tokens)]\n",
    "    conlltags = [(token, pos, tg) for token, pos, tg in zip(tokens, pos_tags, tags)]\n",
    "    ne_tree = conlltags2tree(conlltags)\n",
    "    original_text = defaultdict(list)\n",
    "    for subtree in ne_tree:\n",
    "        original_string = []\n",
    "        if type(subtree) == Tree:\n",
    "            original_label = subtree.label()\n",
    "            leaves = subtree.leaves()\n",
    "        else:\n",
    "            leaves = [subtree]\n",
    "        for token, pos in leaves:\n",
    "            token = token.replace('##', '')\n",
    "            re_dict_json[re_find_which_pattern(token)] +=1 \n",
    "            original_string.extend([(token, int(re_dict_json[re_find_which_pattern(token)]))])\n",
    "        if original_string:\n",
    "            try:\n",
    "                original_text[original_label.lower()].append(original_string)\n",
    "            except:\n",
    "                pass\n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "json_data = {}\n",
    "for key, value in result_data.items():\n",
    "    json_data[key] = get_result_json(value)\n",
    "    new_json_data = {}\n",
    "    for k, v in json_data[key].items():\n",
    "        v = sorted(v, key=lambda e: -len(e))[0]\n",
    "        words = [re_data[key][re_find_which_pattern(word)][count-1] \n",
    "                 if re_find_pattern(word) else word \n",
    "                 for word, count in v]\n",
    "        if words:\n",
    "            words = [re.escape(word) for word in words if word.strip()]\n",
    "            pattern = '\\s*'.join(words)\n",
    "            try:\n",
    "                v_with_space = list(filter(lambda e: e, re.findall(pattern, data_dict[key])))\n",
    "                new_json_data[k] = v_with_space\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    json_data[key] = new_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_data = {}\n",
    "for key, value in json_data.items():\n",
    "    new_dict = defaultdict(str)\n",
    "    for k, v in value.items():\n",
    "        if v:\n",
    "            if k == 'total':\n",
    "                try:\n",
    "                    v = max(list(map(lambda e: float(e), v)))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            else:\n",
    "                v = v[0]\n",
    "        else:\n",
    "            v = ''\n",
    "        new_dict[k] = str(v).replace('\\n', ' ').replace('\\t', ' ')\n",
    "        if not new_dict['total']:\n",
    "            new_dict['total'] = max(list(map(lambda e: float(e),re_data[key]['float'])))\n",
    "    new_json_data[key] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '/home/long8v/docrv2_sroie/submission/SROIE_example_t3'\n",
    "for key, value in new_json_data.items():\n",
    "    with open('{}/{}.txt'.format(path, key), 'w') as f:\n",
    "        f.write('{\\n')\n",
    "        f.write('    \"company\": \"{}\",\\n'.format(value['company']))\n",
    "        f.write('    \"date\": \"{}\",\\n'.format(value['date']))\n",
    "        f.write('    \"address\": \"{}\",\\n'.format(value['address']))\n",
    "        f.write('    \"total\": \"{}\"\\n'.format(value['total']))\n",
    "        f.write('}')\n",
    "#         print('{} saved.'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip saved!\n"
     ]
    }
   ],
   "source": [
    "in_path = '/home/long8v/docrv2_sroie/submission/SROIE_example_t3'\n",
    "out_path = '/home/long8v/docrv2_sroie/submission/SROIE_example_t3'\n",
    "out_zip_file = '/home/long8v/docrv2_sroie/evaluation/task3/submit.zip'\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "submission_zip = zipfile.ZipFile(out_zip_file, 'w')\n",
    "for folder, subfolders, files in os.walk(in_path): \n",
    "    for file in files:\n",
    "        submission_zip.write(os.path.join(folder, file), \n",
    "                             os.path.relpath(os.path.join(folder,file), out_path), \n",
    "                             compress_type = zipfile.ZIP_DEFLATED)\n",
    "print('zip saved!')\n",
    "submission_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_hugging_face",
   "language": "python",
   "name": "huggin_face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
